\section{Introduction}
%123456789123456789123456789123456789123456789123456789123456789
The increasing demands of services and computational applications 
from {\sc ict}--related products significantly contribute
to the increase of energy consumption.{\footnote{Although in the physical sense energy 
		cannot be consumed, we will use the terms energy ``consumption'', 
		``requirement'', and ``usage'' to refer to the conversion of 
		electrical energy by {\sc ict} equipment into thermal energy 
		dissipation to the environment. 
		Correspondingly, we will use the term energy ``savings", 
		``reduction", ``efficiency", and ``optimization" to refer 
		to reduced consumption}} 
Recent research conducted by Gelenbe and Caseau~\shortcite{ICT_energy_impact_1} and 
Van Heddeghem et al.~\shortcite{ICT_energy_impact_2} indicates a 
rising trend of the {\sc it} sector's energy requirements.
It is expected that these requirements will reach 15\% of the world's total energy consumption 
by 2020. 

%Moreover, results in {\sc smart}er2030\footnote{http://smarter2030.gesi.org/downloads.php} report an increase of green house gas emissions due to the it-sector.  IT-related gas emissions are growing much faster than initially predicted and are estimated at around 2.3\% of total gas emissions globally. 
%Therefore, providing energy efficiency at different fields of 
%{\sc it} is essential and of paramount importance, it is not only an economic issue, but also an issue of environmental concern. 

%123456789123456789123456789123456789123456789123456789123456789
% Why is importat for software engineering and what are the 
% current trend and goal show the scale of a change...
Most of the studies on energy efficiency
have considered energy consumption at hardware level. 
However, there is much of evidence that software can also 
significantly alter energy dissipation~\cite{eder_energy_consumptions, 
capra_is_2012, ferreira_seflab_2013}. 
Therefore, many conference tracks (\textit{e.g.} {\sc greens},\footnote{http://greens.cs.vu.nl/} 
eEnergy)\footnote{http://conferences.sigcomm.org/eenergy/2017/cfp.php}
have recognized the energy--efficiency at the software level
as an emerging research challenge
regarding the implementation of modern systems.

%In fact, some researchers showed by using inefficient data structures 
%or design patterns can increase energy dissipation from 300\% to 700\% 
%respectively \cite{sahin_initial_2012, hasan_energy_profile_for_java_collection_classes_2016}. 
%Nevertheless, even by altering application's energy usage a little 
%bit it can contribute to large scale effect, especially 
%with the large amount of Android smart-phone users 
%amount of available {\sc pc}-like mobile devices, according 
%to Gartner,\footnote{http://www.gartner.com/newsroom/id/3609817} and 
%data-centers.


%123456789123456789123456789123456789123456789123456789123456789
%How to achieve this and 
Nowadays, software has been shifted from traditional 
monolithic architectures to more agile ones, including micro-services. 
The main characteristic of this approach is the development of independent and 
reusable small services in a variety of programming languages.
However, there is a limited number of research works
that examine the energy impact of programming tasks implemented in different 
programming languages.


To identify trends and possible gains regarding the reduce of energy 
consumption, during software development, we conducted an empirical 
study using data from the Rosetta Code Repository.
Our goal is to elicitate energy usages from small 
tasks implemented in a variety of popular
programming languages.
To this end, our results show \textit{which} of the interpreted and 
compiled programming languages offer more energy efficient implementations 
for specific tasks. 
Moreover, we show the negative impact of choosing an inefficient implementation.


%123456789123456789123456789123456789123456789123456789123456789
%Paper's remainder.
The remainder of this paper is organized as follows.
Section~\ref{experiment_setup} describes: 1) our experimental 
setup, 2) our dataset's cleaning method, 3) the software and hardware 
tools we used, and 4) our analysis methodology. 
In Section~\ref{results_and_discussion}, we present our preliminary 
results and in Section~\ref{threats_of_validity} we discuss 
potential threats to validity.
In Section~\ref{related_work}, we list prior work done in the 
field and compare it with ours.
Finally, we conclude in Section~\ref{conclusiona_and_future_work} 
and we present future research directions.

\section{Experimental Setup} \label{experiment_setup}
%123456789123456789123456789123456789123456789123456789123456789
In this Section, we describe our approach for conducting  
our experiment and for retrieving measurements. 
Initially, we provide information about the obtained dataset 
and the way we selected our tasks and refine it. 
Furthermore, we explain our experimental setup, the hardware and 
software tools we used. 

\begin{table}
	\begin{threeparttable}
		\caption{Programming Languages, Compilers and Interpreters}
		\label{Languages_Compilers_and_Interpreters}
		\begin{tabular}{cll}
			\toprule
			& Programming  & Compilers and  \\
			& Languages  &  Interpreters version\\
			\midrule
			Compiled&C, C++	& gcc version 6.3.1 20161221- \\
			&Go		& go version go1.7.5  \\
			&Rust	& rustc version 1.18.0 \\
			\midrule
			Semi-&{\sc vb.net} & mono version 4.4.2.0 (vbnc)\\
			Compiled&C\#		& mono version 4.4.2.0 (mics)\\
			&Java	& javac version 1.8.0\_131 \\
			\midrule
			Interpreted&JavaScript & node version 6.10.3 \\
			&Perl	& perl version 5.24.1 \\
			&{\sc php}		& php version 7.0.19 \\
			&Python	& python version 2.7.13 \\
			&R		& Rscript version 3.3.3 \\
			&Ruby	& ruby version 2.3.3p222 \\
			
			&Swift 	& swift version 3.0.2 \\
			
			\bottomrule
		\end{tabular}
		
	\end{threeparttable}
\end{table}

%\begin{table}
%		\caption{Optimization Options for Compilers}
%		\label{optimization flags}
%		\begin{tabular}{lll}
%			\toprule
%			Programming & Optimization   	& Explanation \\
%			Languages  	&  	Option					&\\
%			\midrule
%			C			& gcc -O3\\
%			C++ 		& g++ -O3\\
%			Go  		& go run -gcflags  	&Active by default, other-\\
%						&	-N				&wise use the -gcflags -N\\
%						&					&option to disable it.\\
%			Rust		& rustc -O \\
%			{\sc vb.net}& vbnc -optimize+,- &+ and - are used to add\\
%			C\#			& mcs -optimize+,- 	& or remove optimization\\
%						&					& respectively.\\
%			Java		& java \{-Djava.		&Avoid usage of \\	
%						&		compiler=NONE\}			& Just-in-Time compiler\\	
%			\bottomrule
%		\end{tabular}
%\end{table}


\subsection{Dataset}
%123456789123456789123456789123456789123456789123456789123456789
In the context of this study, we used the Rosetta 
Code,\footnote{http://rosettacode.org/wiki/Rosetta\_Code} which is a 
publicly available programming chrestomathy site that offers 
851 tasks, 230 draft tasks, and a collection of 658 different 
programming languages. In general, not all tasks are implemented, and not all tasks are possible to implement in all languages.  
For our study, we cloned a Github repository\footnote{https://github.com/acmeism/RosettaCodeData} 
that contains all the currently implemented tasks introduced in 
the Rosetta Code website.

%123456789123456789123456789123456789123456789123456789123456789
To select popular programming languages, we consulted the website 
of tiobe,\footnote{https://www.tiobe.com/tiobe-index/} a software 
quality company.
Tiobe uses a search query for index rating of the most popular 
programming languages around the web on a monthly basis. 
This query is based on a 
formula\footnote{https://www.tiobe.com/tiobe-index/programming-languages-definition/} 
that uses the highest ranked search engines 
(according to Alexa)\footnote{http://www.alexa.com/} and a 
number or requirements enlisted for the programming languages.
We decided to chose the top 15 programming languages 
enlisted for June 2017. 
From the current list, we excluded programming languages such as 
Delphi (not available for Linux OS we are using) and Assembly (different 
implementations between processor architectures). 
In contrast, we included Rust in our dataset that is a memory safe 
programming language and is gaining vast popularity in the web. \
Therefore, we ended up with 14 programming languages as it is illustrated 
in Table~\ref{Languages_Compilers_and_Interpreters}.

%123456789123456789123456789123456789123456789123456789123456789 
To select the examined tasks, we developed a shell script (see 
Subsection~\ref{software_components}) to identify 
which of the 851 tasks offer the most implementations for the 
programming languages of our selection.
After launching our script, we obtained around 29 different tasks. 
For the context of our preliminary study, we chose only 
nine tasks implemented in the most of the programming languages 
of our selection. 
The selected tasks were: \textit{array-concatenation, classes} 
(creating an object and calling a method to print a variable's value), 
\textit{url-encoding and decoding, bubble-, quick-, insertion-, merge-, 
	and selection- sorting algorithms}.
Moreover, to further refine our dataset we used the following steps: 

\begin{enumerate}
	\item [$\bullet$] Some of the tasks offered more than one implementation 
	for the same programming language. 
	Thus, we had to browse manually through each directory and remove 
	them until we had only one that is consistent with the other 
	implementation. 
	For instance, when most of the implemented tasks used iterative implementation, 
	we removed the ones using recursion. 
	\item [$\bullet$] The Java file names and their public names where different 
	which resulted in compilation error. 
	Thus, we had to manually change them.
	\item [$\bullet$] Some of the implementations did not have main 
	classes, or the same data with other tasks. 
	Therefore, we changed the source code to offer consistency.
	\item [$\bullet$] For some programming languages that do not offer 
	the class option such as C and Go, we used {\tt structs}. 
	\item [$\bullet$] Some of the tasks were relatively small and 
	finished faster than a second which makes it impossible for our 
	power analyzer to capture those results. 
	Therefore, we added all the selected tasks in an iteration loop of 
	a million times. 
\end{enumerate}

After applying the above modifications on our dataset, we categorized our 
programming languages in three main categories, namely, compiled, 
semi-compiled, and interpreted (see Table~\ref{Languages_Compilers_and_Interpreters}). 
For the programming languages which offer a semi-compiled approach 
such as Java, {\sc vb.net}, and C\#, we added them under the category of 
compiled languages for our experiments. 
In addition, we compared the compiled and semi-compiled implementations while 
having scenarios with and without compiler optimizations.


\subsection{Hardware and Software components}

%\begin{table}
%	\begin{threeparttable}
%		\caption{System hardware and software specifications}
%		\label{laptop_specs}
%		\begin{tabular}{cl}
%			\toprule
%			&Description\\
%			\midrule
%			Hardware	& \textbf{HP EliteBook 840 G3}, Intel Core i7-6500U \\
%			& (2 physical cores of 2.5 GHz), 8 GB DDR4  \\
%			& memory, 256 GB {\sc ssd}  hard disk, \\
%			& \textbf{Raspberry Pi Model 3b}, 4x ARM A53 \\
%			& 1.2GHz, 2 GB LPDDR2 memory, 64 GB SD\\
%			Operating  System & Fedora 25 kernel version 4.11.5-200,  \\
%			& Raspbian\\	
%			Software 	& {\sc wup} software (retrieving measurements \\
%			& from the device), bash script, Gnuplot 5.0 \\
%			\bottomrule
%		\end{tabular}
%	\end{threeparttable}
%\end{table}


\subsubsection{Hardware Components}
%123456789123456789123456789123456789123456789123456789123456789 
The physical tools we used comprise: 1) portable personal 
computer (HP EliteBook 840 G3),\footnote{http://www8.hp.com/us/en/products/laptops/product-detail.html?oid=7815294\#!tab=specs} 
2) real-time electricity usage monitoring tool, and 
3) embedded device.
The real-time power usage tools we used is the Watts Up 
Pro ({\sc wup}).\footnote{https://www.wattsupmeters.com/secure/products.php?pn=0} 

In general, there are two venues for retrieving energy consumption 
from a computer-based system. 
On the one hand, this is achievable by indirect energy measurements 
through estimation models or performance counters, core component 
of software monitoring tools. 
On the other hand, via direct measurement, hardware power analyzers 
and sensors.  
However, each of these approaches has its own pitfalls. The direct approach 
\textit{, i.e.,} hardware components,  offers coarse-grained 
measurements for the whole systems' energy consumption and low sampling 
rate. 
The indirect approach \textit{, i.e.,} software components, suffers 
from inaccuracy, lack of interoperability, and additional system 
overhead, while using indirect measurements. 
In our research, we decided to use a direct approach such as {\sc wup} since it 
does not have software constrains and is relatively cheap to buy.

In regards to {\sc wup}, it offers accuracy of \textpm1.5\% and 
as minimum sampling rate of a second. 
In order to retrieve power-related measurements from the {\sc wup}, 
we used a Linux-based interface utility available in a Git 
repository.\footnote{https://github.com/pyrovski/watts-up}
This software helped us to retrieve measurements such as timestamps, 
watts, volts, amps, and so on through a mini {\sc usb} interface after 
we integrated its code in our script that runs all the tasks. 
In order to avoid additional overhead in our measurements, we 
connected {\sc wup} mini-{\sc usb} on a Raspberry Pi\footnote{https://www.raspberrypi.org/products/raspberry-pi-3-model-b/} 
to retrieve power consumption from our test-bed.  

\begin{figure}
	\centering
	\includegraphics[width=9cm,height=10cm,keepaspectratio]{"Graph_Graph-Total-Energy_compiled_Optimization_OFF"}
	\caption{ Energy Consumption for Compiled Programming Languages Optimization: OFF}
	\label{Compiled with No Optimization Total}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=9cm,height=10cm,keepaspectratio]{"Graph_Graph-RunTime-Performance_compiled_Optimization_OFF"}
	\caption{ Run-time Performance for Compiled Programming Languages Optimization: OFF}
	\label{Performance Compiled with No Optimization Total}
\end{figure}

\subsubsection{Software Components} \label{software_components}
%123456789123456789123456789123456789123456789123456789123456789 
To extract data, manage, and use our Rosetta Code Repository, 
we developed a number of shell scripts as enlisted below, which are 
publicly available on our Git repository.\footnote{https://github.com/stefanos1316/Rosetta-Code-Research} 

\begin{enumerate}
	\item [$\bullet$] \textbf{script.cleanAll}: removes the current instance 
	of tasks in the current working directory and copy the new one found 
	from in the parent directory. 
	\item [$\bullet$] \textbf{script.findCommonTasksInLanguages}: provides 
	a list of tasks with the number of existing implementations in different languages.
	\item [$\bullet$] \textbf{script.createNewDataSet}: filters the Rosetta 
	Code current dataset and removes programming languages and tasks not 
	added as command line arguments.
	\item [$\bullet$] \textbf{script.fromUpperToLower}: changes the current 
	instance of tasks directories and files from upper to lower 
	case. 
	\item [$\bullet$] \textbf{script.compileTasks}: compiles all tasks found 
	under the tasks' directory and produces error reports if a task fails to 
	compile.
	\item [$\bullet$] \textbf{script.executeTasksRemotely}: executes all the tasks' 
	implementations found under tasks directory. 
	Moreover, it sends command to {\sc wup}, retrieves measurements and stores 
	them on remote host, through \textit{ssh}, in order to start retrieving 
	measurements for each test case. 
	\item [$\bullet$] \textbf{script.createPlottableData}: creates a single file 
	that enlists all the executed tasks with the energy consumption for each 
	implementation. In addition, we used {\sc ntp}\footnote{http://www.ntp.org/} to 
	synchronize both system clocks which helped us to map our results of 
	run-time performance and energy consumption. 
	\item [$\bullet$] \textbf{script.plotGraphs}: after retrieving our data 
	we use this script to plot our graphs. 
	For plotting our graphs we used Gnuplot,\footnote{http://www.gnuplot.info/} 
	an open-source general purpose pipe-oriented plotting tool.
\end{enumerate}

%123456789123456789123456789123456789123456789123456789123456789 
Note that most of the scripts offer the \textit{--help} option 
that shows a list of available command line arguments and options.
In addition, we provide a {\sc readme.md} file, available in our 
repository, as a guideline for using our scripts and reproducing 
the obtained results.  

\begin{figure}
	\centering
	\includegraphics[width=9cm,height=10cm,keepaspectratio]{"Graph_Graph-Total-Energy_compiled_Optimization_On"}
	\caption{ Energy Consumption for Compiled Programming Languages Optimization: On}
	\label{Compiled with Optimization Total}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=9cm,height=10cm,keepaspectratio]{"Graph_Graph-RunTime-Performance_compiled_Optimization_On"}
	\caption{Run-time Performance for Compiled Programming Languages Optimization: On}
	\label{Performance Compiled with Optimization Total}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=9cm,height=10cm,keepaspectratio]{"Graph_Graph-Total-Energy_interpreted"}
	\caption{ Energy Consumption for Interpreted Programming Languages}
	\label{Interpreted Total}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=9cm,height=10cm,keepaspectratio]{"Graph_Graph-RunTime-Performance_interpreted"}
	\caption{Run-time Performance for Interpreted Programming Languages}
	\label{Performance Interpreted Total}
\end{figure}

\subsection{Retrieving Energy Measurements} 
%123456789123456789123456789123456789123456789123456789123456789 
As an initial step for our experiment, we shut down background 
processes, as suggested by Hindle~\shortcite{hindle_greenminer:_2014}, 
found in modern {\sc os} (Operating System) such as disk defragmentation, virus 
scanning software, {\sc cron} jobs, automatic updates, 
disk indexing, document indexing, {\sc rss} feed updates, and so on to 
minimize possible noise interferences in our measurements. 
Making the following steps, we reduced our platform's idle 
power consumption from 8,6 to 5.8 watts on average. 

%123456789123456789123456789123456789123456789123456789123456789 
To prevent addition noise in our results, we estimated that is 
necessary to wait for a short period to reach a 
\textit{stable condition} (where the {\sc wup} shows a stable 
idle time) which is close to five minutes \cite{carroll_analysis_2010}.


After reaching the \textit{stable condition}, we launched our main 
script \textit{i.e.,} \textbf{script.executeTasksRemotely}, 
that executes all the tasks implemented in different programming 
languages. 
Before executing a task, the execution script sends a command 
to the remote host ,\textit{i.e.,} Raspberry Pi, through a 
password-less {\sc ssh} connection to start 
collecting power consumption measurements from {\sc wup} 
for the currently executing task. 
In addition, the local host retrieves run-time performance 
measurements through command 
time\footnote{https://linux.die.net/man/1/time} and stores them 
in timestamped directories which we analyze later.
Between each execution of a task, we added a 
sleep\footnote{http://man7.org/linux/man-pages/man3/sleep.3.html} 
period of three minutes. 
The time gap exists to ensure that our experimental platform 
reached a \textit{stable condition} and to avoid unnecessary noise 
in our measurements. 
For example, to ensure the platform's {\sc cpu} is cooled down 
and the fan is no longer consuming more power.


\begin{table}
	\begin{threeparttable}
		\caption{Comparative Results show the percentage of increased energy usage while using the inefficient implementation in compare to the efficient}
		\label{Interpreted Energy Results}
		\begin{tabular}{llll}
			\toprule
			Tasks Name	& \multicolumn{2}{c}{Implementations} & Comparative\\
						& Efficient	& Inefficient	& Results\\
			\midrule
			Array-Concat& {\sc php}, Ruby	& Swift			& 888.25\% \\
			Classes		& {\sc php}		& Python		& 1616.36\% \\
			Bubble		& JavaScript& Swift			& 12694\% \\
			Insertion	& JavaScript& Perl			& 9430.25\% \\
			Merge		& JavaScript& R 			& 2894.81\% \\
			Quick 		& {\sc php}		& Swift			& 1212.23\% \\
			Selection	& JavaScript& R				& 6657.71\% \\
			Url-Decode	& {\sc php}		& Python		& 2963.05\% \\
			Url-Encode	& {\sc php}		& R				& 3239.79\% \\
			\bottomrule
		\end{tabular}
	\end{threeparttable}
\end{table}


\section{Results and Discussion} \label{results_and_discussion}
%123456789123456789123456789123456789123456789123456789123456789 
For some tasks, the execution time waas less than a second. This 
fact explains the zeros shown in our graphs since it is impossible 
for {\sc wup} to collect measurements that have duration less 
than a second of time interval.
Figure~\ref{Compiled with No Optimization Total} illustrates 
the total energy required for each task implementation to execute 
with no compiler optimization.
The results depict that Java and Rust have the highest 
energy consumption among the compiled programming languages while 
Go has the lowest.  
Also, the results in Figure~\ref{Performance Compiled with No Optimization Total} 
show that energy consumption is directly affected by the run-time 
performance in all cases except for Rust. 
In case of Rust, the energy consumption is kept relatively high 
the run-time performance is not affected negatively like in 
Java.


%123456789123456789123456789123456789123456789123456789123456789 
Figure~\ref{Compiled with Optimization Total} shows the total 
energy dissipation from the beginning until the end of a task 
(while making use of the compiler optimizations).
The obtained results show the use of compiler optimizations 
reduces energy usage in most of the cases while it increases 
it in others. 
For C\#, the energy usage of \textit{quick-, 
	insertion-, bubble- sort} and \textit{url-decode} increased in range of 
1\% to 10\% whereas for \textit{merge-, selection- sort, classes} and 
\textit{url-encode} reductions were between 3.8\% and 36.6\%. 
C's \textit{gcc -O3} achieved energy reductions ranging from 43.36\% 
to 99.6\% for the majority of tasks apart from \textit{url-decoding} 
where the energy increased to 14.7\%.
In the case of C++, the \textit{g++ -O3} resulted in energy savings 
between 0.9\% to 84.71\% for all tasks except for the \textit{url-decoding} 
that introduced increased energy usage of 33.33\%.
For Go most of sorting algorithms and \textit{url-decoding} energy 
usage reductions were ranging from 14.39\% to 31.35\% while for \textit{insertion-sort} 
and \textit{url-encoding} increased between 15.38\% to 62\%. 
Java was the only programming language with energy reduction for 
all tasks, in range of 6\% to 98.4\%.
In the case of Rust, energy requirements for all tasks, reduced in 
range of 15.8\% to 97.7\% apart from the \textit{classes} task 
where the energy usage increased to 15.4\%. 
Regarding {\sc vb.net}, the compiler optimization had very small 
impact on energy consumption; less than 10\%.


%123456789123456789123456789123456789123456789123456789123456789 
For the interpreted programming languages, we can see that the 
energy consumption among them is significantly different as 
depicted in Table~\ref{Interpreted Energy Results}. 
The most inefficient case is Swift that consumes 12694\% more energy 
compares to JavaScript. 
In general, {\sc php}, Ruby, and JavaScript achieved the most energy efficiency 
compared to Swift, R, Perl, and Python where their implementations 
contributed to the highest energy consumption. 
In terms of run-time performance, Figure~\ref{Performance Interpreted Total} 
results show the energy consumed by the interpreted tasks (see Figure~\ref{Interpreted Total}) 
have a relationship with the execution time.


\section{Threats to validity} \label{threats_of_validity}
%123456789123456789123456789123456789123456789123456789123456789 
\noindent\textbf{Internal:} In order to avoid additional overhead 
in our experimental platform, we used a remote host to collect our 
results. 
Therefore, the need of a wireless connection was necessary, which 
might result on additional energy requirements (by making use of 
the {\sc ssh} to start and stop the {\sc wup}). 
Moreover, we cannot have full control of our {\sc os} workloads 
and background operations. 
Therefore, is possible that some daemons might start running 
while testing our experiment. 

%123456789123456789123456789123456789123456789123456789123456789
\noindent\textbf{External:} Our real-time power analyzer offers 
minimum sampling interval of a second. 
In Figures~\ref{Compiled with No Optimization Total}, 
~\ref{Compiled with Optimization Total}, and ~\ref{Interpreted Total}  
the energy dissipation results to zero can be interpreted as follows.
When the tasks execution is less than a seconds, this makes it 
impossible for {\sc wup} to capture such measurements. 
%In addition, during the time duration of a second (required from the 
%{\sc wup} to collect measurements) many events may appear that 
%consumes energy and it is hard to capture them. 
%Therefore, in order obtain these results it is necessary to 
%execute the whole experiment multiple of times and provide statical 
%analysis to have an approximation of the total energy consumption 
%for each task which our current work does not provide yet.


\section{Related Work} \label{related_work}
%123456789123456789123456789123456789123456789123456789123456789
Most empirical studies evaluate software projects
from particular programming language families.
Here, we count the energy consumption of programming tasks across 
14 programming languages.
To the best of our knowledge, this is the first study that assesses 
the energy consumption in different programming languages using 
the Rosetta Code Repository.
In the following, we present related work to our topic and compare 
our results with the results from previous studies.

% Programming languages
\subsection{Programming Languages}
%123456789123456789123456789123456789123456789123456789123456789
Studies regarding the strengths and weaknesses of different 
programming languages can help developers to decide {\it which} 
programming language they will use to perform specific 
programming tasks.
For instance, if programmers aim at the scalability and performance 
of their systems, they use functional programming most of the 
times.
On the other hand, when they want to develop programs with high 
modularity, they use object-oriented programming languages.

%123456789123456789123456789123456789123456789123456789123456789
Closest to our paper is the empirical study that Nanz and Furia
conducted on the Rosetta Code Repository to compare the efficiency 
of eight popular programming languages, including C, Go, C\#, Java, 
F\#, Haskell, Python, and  Ruby~\cite{NF15}.
Contrary to this work, we used a power analyzer to run programming 
tasks on 14 different programming languages in order to compare the 
energy consumption at runtime.

%123456789123456789123456789123456789123456789123456789123456789
In addition, Meyerovich and Rabkin conducted an empirical study 
by analyzing 200,000 SourceForge projects and asking almost 
13,000 programmers to identify characteristics that lead the 
latter to select appropriate programming languages in business 
level~\cite{MR13}.
However, this study is a survey on the adoption of programming 
languages in the industry.
Our goal here is different.
We compare the energy consumption of programming tasks
performed in several programming languages.


\subsection{Energy Consumption and Performance}
%123456789123456789123456789123456789123456789123456789123456789
Several researchers have investigated the energy efficiency and 
run-time performance impact over different programming languages.
Also, a significant amount of works have taken into account the 
execution environment where the programs can run efficiently.

In particular, Abdulsalam et al. conducted experiments on 
workstations~\cite{ALG14}, whereas Rashid et al. on an embedded 
system~\cite{RAT15} and Chen and Zong on 
smart-phones~\cite{chen_android_2016}.
Abdulsalam et al. evaluated the energy effect of four memory
allocation choices ({\tt malloc}, {\tt new}, {\tt array}, and 
{\tt vector}) and they showed that {\tt malloc} is the most 
efficient in terms of energy and performance~\cite{ALG14}.
Chen and Zong showed by using the Android Run Time environment instead 
of Dalvik, that the energy and performance implications of Java
are similar to C and C++~\cite{chen_android_2016}.
Finally, Rashid et al. compared the energy and performance impact of four 
sorting algorithms written in three different programming 
languages ({\sc arm} assembly, C/C++, and Java). 
They found that Java consumes the most energy~\cite{RAT15}.
From all these studies it seems that Java and Python consume a 
lot of energy and perform slowly in comparison with C/C++ and 
Assembly.

%123456789123456789123456789123456789123456789123456789123456789
Additionally, many empirical studies have assessed the impact
of coding practices
(e.g. the use of {\tt for} loops, getters and setters,
static method invocation, views and widgets, and so on)
regarding energy consumption.
Characteristically, Tonini et al. conducted a study on Android 
applications and found that the use of {\tt for} loops with 
specified length and the access of class variables without 
the use of getters and setters can reduce the amount of the 
energy that the applications consume~\cite{TFM13}.
Furthermore, in their study, Linares-Vsquez et al. performed 
analysis over 55 Android applications from various domains
and they reported the most energy consuming {\sc api} 
methods~\cite{LBB14}.
For instance, they found that the 60\% of the energy-greedy 
{\sc api}s, 37\% were related to the graphical user interface and
image manipulation, while the remaining 23\% were associated 
with the database.

Contrary to previous works, here we compare energy consuming 
programming tasks in more than 14 programming languages.
Our results show that significant diverge with respect to 
energy consumption exist for interpreted programming languages. 
Moreover, we provide comparison in programming languages such 
as Go, Rust, {\sc vb.net}, and C\# which is not available in 
prior works.


\section{Conclusions and Future Work} \label{conclusiona_and_future_work}
%123456789123456789123456789123456789123456789123456789123456789 


Nowadays, software development has been shifted from
monolithic to more agile architectures, such as micro-services.
This imposes the {\emph energy efficient} development of independent and reusable
small services in a variety of programming languages.
Goal of this paper is to compare the energy consumption
of specific programming tasks in different programming languages
and identify {\emph which} languages are appropriate to be used in modern services.
In brief, we conducted an empirical study
using a power analyzer to measure the energy consumption
of several programming tasks found in the Rosetta Code Repository,
for 14 popular programming languages.

%123456789123456789123456789123456789123456789123456789123456789 
According to our findings,
the average energy consumption---for the tested tasks---of 
compiled programming languages
seems to be much lower compared to this of the interpreted ones.
Overall, our experiments revealed that {\sc vb.net} and Swift are 
the most inefficient programming languages among the compiled 
and interpreted, respectively.
In particular, compiled programming languages, such as 
C and C++ ,that have the optimization option enabled,
record low average energy usage, whereas Go presents the lowest 
total energy consumption for sorting algorithms. 
Regarding interpreted programming languages,
JavaScript indicates the highest level of energy--efficiency.
On the other hand, Swift seems to consume the most energy in total.

%123456789123456789123456789123456789123456789123456789123456789 
As far as future work is concerned,
we would like to test all the 29 collected 
tasks and, furthermore, to implement and evaluate additional ones,
including exception handling,
and particular tasks for functional programming. 
Moreover, we will test the collected tasks in different {\sc cpu} 
architectures, such as {\sc amd} and {\sc arm}. 
We, also, plan to collect resource usages to identify 
possible relationships between programming  languages and resources. 
To this end, we expect that the obtained results can shed light
on how to efficiently develop larger and more complex applications.

\begin{acks}
	The authors would like to thank Dr. Vasiliki Efstathiou for her 
	valuable help to complete this paper.
\end{acks}


